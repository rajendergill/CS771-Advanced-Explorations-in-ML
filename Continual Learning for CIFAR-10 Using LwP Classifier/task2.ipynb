{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Task 2"
      ],
      "metadata": {
        "id": "X3XhVOH4bP8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import os\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"All Necessary Libraries Imported\")"
      ],
      "metadata": {
        "id": "zXqlMa7vk2qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a99b5c9-dc42-444b-b474-7dfac4ed17f3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Necessary Libraries Imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Models from task 1 to use f10 in this task\n",
        "models_task1 = torch.load(\"/content/drive/MyDrive/models_task1.pth\")\n",
        "print(type(models_task1))\n",
        "print(len(models_task1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xJkmtxq6L7z",
        "outputId": "b8f05084-de6a-4063-d276-176622e632d6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-2dec1fba0a1f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  models_task1 = torch.load(\"/content/drive/MyDrive/models_task1.pth\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Device Selected {device}\")"
      ],
      "metadata": {
        "id": "SND1lMLJk5HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0799e55b-2350-4133-8193-1e598790c47c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Selected cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.images = data['data']\n",
        "        self.labels = torch.tensor(data['targets']) if 'targets' in data else None\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.fromarray(self.images[idx])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx] if self.labels is not None else -1\n",
        "        return img, label\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(data, feature_extractor, batch_size=32):\n",
        "    dataset = CustomImageDataset(data, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    features, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels_batch in loader:\n",
        "            images = images.to(device)\n",
        "            batch_features = feature_extractor(images).view(images.size(0), -1)  # Flatten\n",
        "            features.append(batch_features.cpu())\n",
        "            labels.append(labels_batch)\n",
        "\n",
        "    return torch.cat(features), torch.cat(labels)\n",
        "\n",
        "# Initialize feature extractor\n",
        "def initialize_feature_extractor():\n",
        "    feature_extractor = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
        "    feature_extractor = feature_extractor.to(device)\n",
        "    feature_extractor.eval()\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "hJMW4QKef7f6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Initialize feature extractor\n",
        "print(\"Initializing feature extractor...\")\n",
        "feature_extractor = initialize_feature_extractor()\n",
        "print(\"Feature extractor initialized!\\n\")\n",
        "\n",
        "# Cache feature extraction for training datasets (D11 to D20)\n",
        "train_features_cache = {}\n",
        "eval_features_cache = {}\n",
        "\n",
        "data_paths_task2 = [f\"/content/drive/MyDrive/dataset/part_two_dataset/train_data/{i+1}_train_data.tar.pth\" for i in range(10)]\n",
        "eval_paths_task2 = [\n",
        "    f\"/content/drive/MyDrive/dataset/part_one_dataset/eval_data/{i+1}_eval_data.tar.pth\" for i in range(10)\n",
        "] + [\n",
        "    f\"/content/drive/MyDrive/dataset/part_two_dataset/eval_data/{i+1}_eval_data.tar.pth\" for i in range(10)\n",
        "]  # 20 heldout datasets\n",
        "\n",
        "# Cache features for training datasets\n",
        "print(\"Caching features for training datasets...\\n\")\n",
        "for i in range(10):\n",
        "    print(f\"Processing training dataset D{i+11}...\")\n",
        "    if i not in train_features_cache:\n",
        "        current_data = torch.load(data_paths_task2[i])\n",
        "        current_features, current_targets = extract_features(current_data, feature_extractor, batch_size=256)\n",
        "        train_features_cache[i] = (current_features, current_targets)  # Cache features and targets\n",
        "\n",
        "\n",
        "# Cache features for evaluation datasets\n",
        "print(\"Caching features for evaluation datasets...\\n\")\n",
        "for j in range(20):\n",
        "    print(f\"Processing evaluation dataset D̂{j+1}...\")\n",
        "    if j not in eval_features_cache:\n",
        "        eval_data = torch.load(eval_paths_task2[j])\n",
        "        eval_features, eval_targets = extract_features(eval_data, feature_extractor, batch_size=256)\n",
        "        eval_features_cache[j] = (eval_features, eval_targets)\n",
        "\n",
        "# Save the cached features\n",
        "print(\"Saving cached features to disk...\")\n",
        "torch.save(train_features_cache, \"/content/drive/MyDrive/train_features_cache2.pth\")\n",
        "torch.save(eval_features_cache, \"/content/drive/MyDrive/eval_features_cache2.pth\")\n",
        "print(\"Cached features saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05BLa6PpjS7B",
        "outputId": "a3650fa2-3498-4f6b-f56d-21227e70aae7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing feature extractor...\n",
            "Feature extractor initialized!\n",
            "\n",
            "Caching features for training datasets...\n",
            "\n",
            "Processing training dataset D11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9edf0c87c1c2>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  current_data = torch.load(data_paths_task2[i])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing training dataset D12...\n",
            "Processing training dataset D13...\n",
            "Processing training dataset D14...\n",
            "Processing training dataset D15...\n",
            "Processing training dataset D16...\n",
            "Processing training dataset D17...\n",
            "Processing training dataset D18...\n",
            "Processing training dataset D19...\n",
            "Processing training dataset D20...\n",
            "Caching features for evaluation datasets...\n",
            "\n",
            "Processing evaluation dataset D̂1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9edf0c87c1c2>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  eval_data = torch.load(eval_paths_task2[j])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing evaluation dataset D̂2...\n",
            "Processing evaluation dataset D̂3...\n",
            "Processing evaluation dataset D̂4...\n",
            "Processing evaluation dataset D̂5...\n",
            "Processing evaluation dataset D̂6...\n",
            "Processing evaluation dataset D̂7...\n",
            "Processing evaluation dataset D̂8...\n",
            "Processing evaluation dataset D̂9...\n",
            "Processing evaluation dataset D̂10...\n",
            "Processing evaluation dataset D̂11...\n",
            "Processing evaluation dataset D̂12...\n",
            "Processing evaluation dataset D̂13...\n",
            "Processing evaluation dataset D̂14...\n",
            "Processing evaluation dataset D̂15...\n",
            "Processing evaluation dataset D̂16...\n",
            "Processing evaluation dataset D̂17...\n",
            "Processing evaluation dataset D̂18...\n",
            "Processing evaluation dataset D̂19...\n",
            "Processing evaluation dataset D̂20...\n",
            "Saving cached features to disk...\n",
            "Cached features saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load cached features\n",
        "train_features_cache = torch.load(\"/content/drive/MyDrive/train_features_cache2.pth\")\n",
        "eval_features_cache = torch.load(\"/content/drive/MyDrive/eval_features_cache2.pth\")\n",
        "\n",
        "# Learning with Prototypes (LWP) model\n",
        "def train_lwp(features, labels):\n",
        "    unique_classes = torch.unique(labels)\n",
        "    class_means = {}\n",
        "    for cls in unique_classes:\n",
        "        class_indices = (labels == cls)\n",
        "        class_means[cls.item()] = features[class_indices].mean(dim=0)\n",
        "    return class_means\n",
        "\n",
        "# Predict using Learning with Prototypes (Batch Processing)\n",
        "def predict_lwp(features, class_means):\n",
        "    # Convert class means to a tensor for batch processing\n",
        "    mean_tensor = torch.stack(list(class_means.values()))\n",
        "    mean_classes = torch.tensor(list(class_means.keys()))\n",
        "\n",
        "    # Calculate distances between features and class means\n",
        "    distances = torch.cdist(features, mean_tensor)\n",
        "    closest_indices = torch.argmin(distances, dim=1)\n",
        "    return mean_classes[closest_indices]"
      ],
      "metadata": {
        "id": "QTLiTCUujTTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966d2a10-ff6b-49b4-81ab-ccd510421eea"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-40e038cae71c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_features_cache = torch.load(\"/content/drive/MyDrive/train_features_cache2.pth\")\n",
            "<ipython-input-56-40e038cae71c>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  eval_features_cache = torch.load(\"/content/drive/MyDrive/eval_features_cache2.pth\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Learning with Prototypes on all datasets for Task 2\n",
        "def task_2_cached(data_paths, heldout_paths, initial_model, train_features_cache, eval_features_cache):\n",
        "    print(\"Starting Task 2 with cached features...\\n\")\n",
        "    models_task2 = [initial_model]  # Start with the initial model\n",
        "    accuracy_matrix = []\n",
        "\n",
        "    for i in range(10):\n",
        "        # Load current dataset D{i+11} from cached features\n",
        "        train_features, train_labels = train_features_cache[i]\n",
        "\n",
        "        # Predict labels for D{i+11} using the last model\n",
        "        pseudo_labels = predict_lwp(train_features, models_task2[-1])\n",
        "\n",
        "        # Update model based on pseudo-labels\n",
        "        updated_class_means = train_lwp(train_features, pseudo_labels)\n",
        "\n",
        "        # Merge the updated class means into the current model\n",
        "        new_model = defaultdict(torch.Tensor)\n",
        "        for cls in updated_class_means:\n",
        "            if cls in models_task2[-1]:\n",
        "                # Weighted average of old and new class means\n",
        "                new_model[cls] = (models_task2[-1][cls] + updated_class_means[cls]) / 2\n",
        "            else:\n",
        "                new_model[cls] = updated_class_means[cls]\n",
        "        models_task2.append(new_model)\n",
        "\n",
        "        # Evaluate the model on all heldout datasets D̂1 to D̂{i+11} using cached evaluation features\n",
        "        print(f\"Evaluating model f{i+11} on datasets...\")\n",
        "        row_accuracies = []\n",
        "        for j in range(i + 11):\n",
        "            eval_features, eval_labels = eval_features_cache[j]\n",
        "            predictions = predict_lwp(eval_features, models_task2[-1])\n",
        "            accuracy = (predictions == eval_labels).float().mean().item() * 100\n",
        "            row_accuracies.append(accuracy)\n",
        "            print(f\"Evaluation on D̂{j+1}: Accuracy = {accuracy:.2f}%\")\n",
        "        accuracy_matrix.append(row_accuracies)\n",
        "        print(f\"Model f{i+11} evaluation completed. Current accuracy matrix row: {row_accuracies}\")\n",
        "\n",
        "    # Print accuracy matrix\n",
        "    print(\"\\nTask 2 Accuracy Matrix:\")\n",
        "    print(\"     \" + \"  \".join([f\"D̂{i+1}\" for i in range(20)]))\n",
        "    for i, row in enumerate(accuracy_matrix):\n",
        "        print(f\"f{i+11}: \" + \"  \".join([f\"{acc:.2f}%\" for acc in row]))\n",
        "\n",
        "    print(\"\\nTask 2 completed successfully!\")\n",
        "    return models_task2, accuracy_matrix\n",
        ""
      ],
      "metadata": {
        "id": "at3wgj3NjaLh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Task 2 using the initial model and cached data\n",
        "models_task2, accuracy_matrix_task2 = task_2_cached(data_paths_task2, eval_paths_task2, models_task1[-1], train_features_cache, eval_features_cache)\n",
        "\n",
        "# Save the Task 2 models\n",
        "torch.save(models_task2, \"/content/drive/MyDrive/models_task2.pth\")"
      ],
      "metadata": {
        "id": "Pd5HQGzIjdF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcd4693-23c7-4013-8d5b-42f29051e692"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Task 2 with cached features...\n",
            "\n",
            "Evaluating model f11 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 84.76%\n",
            "Evaluation on D̂2: Accuracy = 86.24%\n",
            "Evaluation on D̂3: Accuracy = 84.96%\n",
            "Evaluation on D̂4: Accuracy = 86.20%\n",
            "Evaluation on D̂5: Accuracy = 85.40%\n",
            "Evaluation on D̂6: Accuracy = 85.40%\n",
            "Evaluation on D̂7: Accuracy = 85.92%\n",
            "Evaluation on D̂8: Accuracy = 85.48%\n",
            "Evaluation on D̂9: Accuracy = 85.60%\n",
            "Evaluation on D̂10: Accuracy = 85.56%\n",
            "Evaluation on D̂11: Accuracy = 72.76%\n",
            "Model f11 evaluation completed. Current accuracy matrix row: [84.7599983215332, 86.23999953269958, 84.96000170707703, 86.19999885559082, 85.39999723434448, 85.39999723434448, 85.92000007629395, 85.47999858856201, 85.6000006198883, 85.55999994277954, 72.75999784469604]\n",
            "Evaluating model f12 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 82.96%\n",
            "Evaluation on D̂2: Accuracy = 83.80%\n",
            "Evaluation on D̂3: Accuracy = 83.16%\n",
            "Evaluation on D̂4: Accuracy = 84.48%\n",
            "Evaluation on D̂5: Accuracy = 83.68%\n",
            "Evaluation on D̂6: Accuracy = 83.36%\n",
            "Evaluation on D̂7: Accuracy = 83.56%\n",
            "Evaluation on D̂8: Accuracy = 83.80%\n",
            "Evaluation on D̂9: Accuracy = 83.00%\n",
            "Evaluation on D̂10: Accuracy = 83.84%\n",
            "Evaluation on D̂11: Accuracy = 70.40%\n",
            "Evaluation on D̂12: Accuracy = 58.48%\n",
            "Model f12 evaluation completed. Current accuracy matrix row: [82.95999765396118, 83.79999995231628, 83.160001039505, 84.47999954223633, 83.67999792098999, 83.35999846458435, 83.56000185012817, 83.79999995231628, 82.99999833106995, 83.84000062942505, 70.39999961853027, 58.480000495910645]\n",
            "Evaluating model f13 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 82.24%\n",
            "Evaluation on D̂2: Accuracy = 83.32%\n",
            "Evaluation on D̂3: Accuracy = 82.76%\n",
            "Evaluation on D̂4: Accuracy = 83.80%\n",
            "Evaluation on D̂5: Accuracy = 83.12%\n",
            "Evaluation on D̂6: Accuracy = 82.84%\n",
            "Evaluation on D̂7: Accuracy = 83.36%\n",
            "Evaluation on D̂8: Accuracy = 82.96%\n",
            "Evaluation on D̂9: Accuracy = 82.64%\n",
            "Evaluation on D̂10: Accuracy = 83.16%\n",
            "Evaluation on D̂11: Accuracy = 70.28%\n",
            "Evaluation on D̂12: Accuracy = 57.44%\n",
            "Evaluation on D̂13: Accuracy = 76.36%\n",
            "Model f13 evaluation completed. Current accuracy matrix row: [82.23999738693237, 83.31999778747559, 82.76000022888184, 83.79999995231628, 83.12000036239624, 82.84000158309937, 83.35999846458435, 82.95999765396118, 82.63999819755554, 83.160001039505, 70.27999758720398, 57.440000772476196, 76.35999917984009]\n",
            "Evaluating model f14 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 82.60%\n",
            "Evaluation on D̂2: Accuracy = 83.64%\n",
            "Evaluation on D̂3: Accuracy = 83.40%\n",
            "Evaluation on D̂4: Accuracy = 84.24%\n",
            "Evaluation on D̂5: Accuracy = 83.72%\n",
            "Evaluation on D̂6: Accuracy = 83.56%\n",
            "Evaluation on D̂7: Accuracy = 84.08%\n",
            "Evaluation on D̂8: Accuracy = 83.32%\n",
            "Evaluation on D̂9: Accuracy = 83.28%\n",
            "Evaluation on D̂10: Accuracy = 83.96%\n",
            "Evaluation on D̂11: Accuracy = 71.28%\n",
            "Evaluation on D̂12: Accuracy = 57.48%\n",
            "Evaluation on D̂13: Accuracy = 76.60%\n",
            "Evaluation on D̂14: Accuracy = 83.20%\n",
            "Model f14 evaluation completed. Current accuracy matrix row: [82.59999752044678, 83.63999724388123, 83.39999914169312, 84.24000144004822, 83.71999859809875, 83.56000185012817, 84.07999873161316, 83.31999778747559, 83.27999711036682, 83.96000266075134, 71.28000259399414, 57.48000144958496, 76.5999972820282, 83.20000171661377]\n",
            "Evaluating model f15 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 83.28%\n",
            "Evaluation on D̂2: Accuracy = 84.44%\n",
            "Evaluation on D̂3: Accuracy = 84.16%\n",
            "Evaluation on D̂4: Accuracy = 84.92%\n",
            "Evaluation on D̂5: Accuracy = 84.28%\n",
            "Evaluation on D̂6: Accuracy = 83.92%\n",
            "Evaluation on D̂7: Accuracy = 84.84%\n",
            "Evaluation on D̂8: Accuracy = 83.64%\n",
            "Evaluation on D̂9: Accuracy = 84.36%\n",
            "Evaluation on D̂10: Accuracy = 84.96%\n",
            "Evaluation on D̂11: Accuracy = 72.00%\n",
            "Evaluation on D̂12: Accuracy = 57.80%\n",
            "Evaluation on D̂13: Accuracy = 76.72%\n",
            "Evaluation on D̂14: Accuracy = 84.00%\n",
            "Evaluation on D̂15: Accuracy = 83.84%\n",
            "Model f15 evaluation completed. Current accuracy matrix row: [83.27999711036682, 84.43999886512756, 84.16000008583069, 84.92000102996826, 84.28000211715698, 83.92000198364258, 84.83999967575073, 83.63999724388123, 84.35999751091003, 84.96000170707703, 72.00000286102295, 57.8000009059906, 76.71999931335449, 83.99999737739563, 83.84000062942505]\n",
            "Evaluating model f16 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 82.16%\n",
            "Evaluation on D̂2: Accuracy = 83.04%\n",
            "Evaluation on D̂3: Accuracy = 82.72%\n",
            "Evaluation on D̂4: Accuracy = 84.00%\n",
            "Evaluation on D̂5: Accuracy = 83.40%\n",
            "Evaluation on D̂6: Accuracy = 82.60%\n",
            "Evaluation on D̂7: Accuracy = 84.04%\n",
            "Evaluation on D̂8: Accuracy = 82.80%\n",
            "Evaluation on D̂9: Accuracy = 82.68%\n",
            "Evaluation on D̂10: Accuracy = 83.20%\n",
            "Evaluation on D̂11: Accuracy = 71.04%\n",
            "Evaluation on D̂12: Accuracy = 55.96%\n",
            "Evaluation on D̂13: Accuracy = 76.40%\n",
            "Evaluation on D̂14: Accuracy = 82.40%\n",
            "Evaluation on D̂15: Accuracy = 82.76%\n",
            "Evaluation on D̂16: Accuracy = 74.48%\n",
            "Model f16 evaluation completed. Current accuracy matrix row: [82.16000199317932, 83.03999900817871, 82.71999955177307, 83.99999737739563, 83.39999914169312, 82.59999752044678, 84.0399980545044, 82.8000009059906, 82.6799988746643, 83.20000171661377, 71.03999853134155, 55.959999561309814, 76.39999985694885, 82.40000009536743, 82.76000022888184, 74.47999715805054]\n",
            "Evaluating model f17 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 82.00%\n",
            "Evaluation on D̂2: Accuracy = 82.64%\n",
            "Evaluation on D̂3: Accuracy = 82.24%\n",
            "Evaluation on D̂4: Accuracy = 83.64%\n",
            "Evaluation on D̂5: Accuracy = 83.12%\n",
            "Evaluation on D̂6: Accuracy = 82.28%\n",
            "Evaluation on D̂7: Accuracy = 83.60%\n",
            "Evaluation on D̂8: Accuracy = 82.32%\n",
            "Evaluation on D̂9: Accuracy = 82.00%\n",
            "Evaluation on D̂10: Accuracy = 82.84%\n",
            "Evaluation on D̂11: Accuracy = 70.88%\n",
            "Evaluation on D̂12: Accuracy = 55.88%\n",
            "Evaluation on D̂13: Accuracy = 75.88%\n",
            "Evaluation on D̂14: Accuracy = 82.20%\n",
            "Evaluation on D̂15: Accuracy = 82.52%\n",
            "Evaluation on D̂16: Accuracy = 74.72%\n",
            "Evaluation on D̂17: Accuracy = 79.44%\n",
            "Model f17 evaluation completed. Current accuracy matrix row: [81.99999928474426, 82.63999819755554, 82.23999738693237, 83.63999724388123, 83.12000036239624, 82.27999806404114, 83.60000252723694, 82.3199987411499, 81.99999928474426, 82.84000158309937, 70.88000178337097, 55.879998207092285, 75.88000297546387, 82.20000267028809, 82.52000212669373, 74.72000122070312, 79.43999767303467]\n",
            "Evaluating model f18 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 80.96%\n",
            "Evaluation on D̂2: Accuracy = 81.88%\n",
            "Evaluation on D̂3: Accuracy = 81.32%\n",
            "Evaluation on D̂4: Accuracy = 83.00%\n",
            "Evaluation on D̂5: Accuracy = 82.56%\n",
            "Evaluation on D̂6: Accuracy = 81.64%\n",
            "Evaluation on D̂7: Accuracy = 82.64%\n",
            "Evaluation on D̂8: Accuracy = 81.20%\n",
            "Evaluation on D̂9: Accuracy = 81.28%\n",
            "Evaluation on D̂10: Accuracy = 82.20%\n",
            "Evaluation on D̂11: Accuracy = 70.52%\n",
            "Evaluation on D̂12: Accuracy = 56.00%\n",
            "Evaluation on D̂13: Accuracy = 75.36%\n",
            "Evaluation on D̂14: Accuracy = 81.80%\n",
            "Evaluation on D̂15: Accuracy = 81.24%\n",
            "Evaluation on D̂16: Accuracy = 73.44%\n",
            "Evaluation on D̂17: Accuracy = 77.80%\n",
            "Evaluation on D̂18: Accuracy = 73.36%\n",
            "Model f18 evaluation completed. Current accuracy matrix row: [80.95999956130981, 81.87999725341797, 81.31999969482422, 82.99999833106995, 82.56000280380249, 81.63999915122986, 82.63999819755554, 81.19999766349792, 81.27999901771545, 82.20000267028809, 70.52000164985657, 56.00000023841858, 75.3600001335144, 81.80000185966492, 81.23999834060669, 73.43999743461609, 77.7999997138977, 73.36000204086304]\n",
            "Evaluating model f19 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 79.28%\n",
            "Evaluation on D̂2: Accuracy = 79.60%\n",
            "Evaluation on D̂3: Accuracy = 79.52%\n",
            "Evaluation on D̂4: Accuracy = 80.48%\n",
            "Evaluation on D̂5: Accuracy = 80.44%\n",
            "Evaluation on D̂6: Accuracy = 79.64%\n",
            "Evaluation on D̂7: Accuracy = 79.76%\n",
            "Evaluation on D̂8: Accuracy = 79.52%\n",
            "Evaluation on D̂9: Accuracy = 78.52%\n",
            "Evaluation on D̂10: Accuracy = 79.92%\n",
            "Evaluation on D̂11: Accuracy = 67.48%\n",
            "Evaluation on D̂12: Accuracy = 54.32%\n",
            "Evaluation on D̂13: Accuracy = 74.32%\n",
            "Evaluation on D̂14: Accuracy = 79.40%\n",
            "Evaluation on D̂15: Accuracy = 78.84%\n",
            "Evaluation on D̂16: Accuracy = 71.96%\n",
            "Evaluation on D̂17: Accuracy = 76.04%\n",
            "Evaluation on D̂18: Accuracy = 71.16%\n",
            "Evaluation on D̂19: Accuracy = 59.92%\n",
            "Model f19 evaluation completed. Current accuracy matrix row: [79.28000092506409, 79.60000038146973, 79.5199990272522, 80.47999739646912, 80.44000267982483, 79.64000105857849, 79.75999712944031, 79.5199990272522, 78.51999998092651, 79.91999983787537, 67.47999787330627, 54.32000160217285, 74.32000041007996, 79.40000295639038, 78.83999943733215, 71.96000218391418, 76.03999972343445, 71.16000056266785, 59.92000102996826]\n",
            "Evaluating model f20 on datasets...\n",
            "Evaluation on D̂1: Accuracy = 80.12%\n",
            "Evaluation on D̂2: Accuracy = 81.08%\n",
            "Evaluation on D̂3: Accuracy = 80.72%\n",
            "Evaluation on D̂4: Accuracy = 81.80%\n",
            "Evaluation on D̂5: Accuracy = 81.60%\n",
            "Evaluation on D̂6: Accuracy = 80.64%\n",
            "Evaluation on D̂7: Accuracy = 81.16%\n",
            "Evaluation on D̂8: Accuracy = 80.12%\n",
            "Evaluation on D̂9: Accuracy = 79.92%\n",
            "Evaluation on D̂10: Accuracy = 80.68%\n",
            "Evaluation on D̂11: Accuracy = 68.64%\n",
            "Evaluation on D̂12: Accuracy = 55.00%\n",
            "Evaluation on D̂13: Accuracy = 75.08%\n",
            "Evaluation on D̂14: Accuracy = 80.44%\n",
            "Evaluation on D̂15: Accuracy = 80.20%\n",
            "Evaluation on D̂16: Accuracy = 72.96%\n",
            "Evaluation on D̂17: Accuracy = 77.48%\n",
            "Evaluation on D̂18: Accuracy = 72.28%\n",
            "Evaluation on D̂19: Accuracy = 58.80%\n",
            "Evaluation on D̂20: Accuracy = 79.52%\n",
            "Model f20 evaluation completed. Current accuracy matrix row: [80.11999726295471, 81.08000159263611, 80.7200014591217, 81.80000185966492, 81.5999984741211, 80.64000010490417, 81.16000294685364, 80.11999726295471, 79.91999983787537, 80.68000078201294, 68.63999962806702, 55.000001192092896, 75.08000135421753, 80.44000267982483, 80.19999861717224, 72.96000123023987, 77.48000025749207, 72.28000164031982, 58.799999952316284, 79.5199990272522]\n",
            "\n",
            "Task 2 Accuracy Matrix:\n",
            "     D̂1  D̂2  D̂3  D̂4  D̂5  D̂6  D̂7  D̂8  D̂9  D̂10  D̂11  D̂12  D̂13  D̂14  D̂15  D̂16  D̂17  D̂18  D̂19  D̂20\n",
            "f11: 84.76%  86.24%  84.96%  86.20%  85.40%  85.40%  85.92%  85.48%  85.60%  85.56%  72.76%\n",
            "f12: 82.96%  83.80%  83.16%  84.48%  83.68%  83.36%  83.56%  83.80%  83.00%  83.84%  70.40%  58.48%\n",
            "f13: 82.24%  83.32%  82.76%  83.80%  83.12%  82.84%  83.36%  82.96%  82.64%  83.16%  70.28%  57.44%  76.36%\n",
            "f14: 82.60%  83.64%  83.40%  84.24%  83.72%  83.56%  84.08%  83.32%  83.28%  83.96%  71.28%  57.48%  76.60%  83.20%\n",
            "f15: 83.28%  84.44%  84.16%  84.92%  84.28%  83.92%  84.84%  83.64%  84.36%  84.96%  72.00%  57.80%  76.72%  84.00%  83.84%\n",
            "f16: 82.16%  83.04%  82.72%  84.00%  83.40%  82.60%  84.04%  82.80%  82.68%  83.20%  71.04%  55.96%  76.40%  82.40%  82.76%  74.48%\n",
            "f17: 82.00%  82.64%  82.24%  83.64%  83.12%  82.28%  83.60%  82.32%  82.00%  82.84%  70.88%  55.88%  75.88%  82.20%  82.52%  74.72%  79.44%\n",
            "f18: 80.96%  81.88%  81.32%  83.00%  82.56%  81.64%  82.64%  81.20%  81.28%  82.20%  70.52%  56.00%  75.36%  81.80%  81.24%  73.44%  77.80%  73.36%\n",
            "f19: 79.28%  79.60%  79.52%  80.48%  80.44%  79.64%  79.76%  79.52%  78.52%  79.92%  67.48%  54.32%  74.32%  79.40%  78.84%  71.96%  76.04%  71.16%  59.92%\n",
            "f20: 80.12%  81.08%  80.72%  81.80%  81.60%  80.64%  81.16%  80.12%  79.92%  80.68%  68.64%  55.00%  75.08%  80.44%  80.20%  72.96%  77.48%  72.28%  58.80%  79.52%\n",
            "\n",
            "Task 2 completed successfully!\n"
          ]
        }
      ]
    }
  ]
}